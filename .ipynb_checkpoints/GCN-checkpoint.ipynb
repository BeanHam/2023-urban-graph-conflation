{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21176085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from karateclub import BoostNE\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d88696",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 graph_dir, \n",
    "                 graph_files):\n",
    "        \n",
    "        self.graph_dir = graph_dir\n",
    "        self.graph_files = graph_files        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graph_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # single graph\n",
    "        file = self.graph_files[idx]\n",
    "        \n",
    "        # graph paths\n",
    "        graph_gt_path = os.path.join(self.graph_dir, 'original', file)\n",
    "        graph_del_path = os.path.join(self.graph_dir, 'deletion', file)\n",
    "        graph_ins_path = os.path.join(self.graph_dir, 'insertion', file)\n",
    "        \n",
    "        # ground truth adj\n",
    "        graph_gt = torch.from_numpy(nx.to_numpy_array(nx.read_gpickle(graph_gt_path))).float()\n",
    "        \n",
    "        # deletion graph embedding\n",
    "        graph_del = nx.read_gpickle(graph_del_path)\n",
    "        graph_ins = nx.read_gpickle(graph_ins_path)\n",
    "        graph_comb = nx.compose(graph_ins, graph_del)\n",
    "        \n",
    "        edge_index = np.array(graph_comb.edges()).T\n",
    "        x = torch.ones(len(graph_comb),1)\n",
    "        \n",
    "        return graph_gt, edge_index, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ce8f0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(1, 32)\n",
    "        self.conv2 = GCNConv(32, 64)\n",
    "\n",
    "    def forward(self, edge_index, x):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        z = F.leaky_relu(x)\n",
    "        \n",
    "        # reconstruct adj\n",
    "        A_tild = torch.matmul(z, z.T)\n",
    "        \n",
    "        return A_tild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cbbc89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "lr = 1e-4\n",
    "epochs = 20\n",
    "batch_size = 1\n",
    "emb_model = BoostNE(dimensions=16, iterations=15)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion= nn.BCEWithLogitsLoss(pos_weight=torch.tensor(10))\n",
    "\n",
    "# load files\n",
    "train_files = os.listdir('../graph-data/seattle-graphs/original/')\n",
    "test_files = os.listdir('../graph-data/west-seattle-graphs/original/')\n",
    "train_files, val_files = train_test_split(train_files, test_size=0.1, random_state=42)\n",
    "\n",
    "# make datasets\n",
    "train_data = GraphDataset('../graph-data/seattle-graphs/', train_files)\n",
    "val_data = GraphDataset('../graph-data/seattle-graphs/', val_files)\n",
    "test_data = GraphDataset('../graph-data/west-seattle-graphs/', test_files)\n",
    "\n",
    "# data loader\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "24cd0bf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7260736227035522\n",
      "1.3084449768066406\n",
      "1.1746248006820679\n",
      "1.1272807121276855\n",
      "1.9075114727020264\n",
      "1.1492056846618652\n",
      "1.5539170503616333\n",
      "1.2490254640579224\n",
      "1.1311674118041992\n",
      "1.1851170063018799\n",
      "1.2541803121566772\n",
      "1.0186675786972046\n",
      "1.431530475616455\n",
      "1.098233699798584\n",
      "1.5818767547607422\n",
      "0.8637858629226685\n",
      "1.3302481174468994\n",
      "1.4458212852478027\n",
      "1.072042465209961\n",
      "1.075125813484192\n",
      "1.1262389421463013\n",
      "1.18251371383667\n",
      "1.639432430267334\n",
      "1.363578200340271\n",
      "1.093266248703003\n",
      "2.067828893661499\n",
      "0.9671208262443542\n",
      "1.2436319589614868\n",
      "1.0350104570388794\n",
      "1.5872247219085693\n",
      "1.1330480575561523\n",
      "0.9363064169883728\n",
      "1.1471842527389526\n",
      "1.3069286346435547\n",
      "1.0812033414840698\n",
      "1.4681980609893799\n",
      "1.1735368967056274\n",
      "1.219736933708191\n",
      "1.4247939586639404\n",
      "1.044346570968628\n",
      "1.0508898496627808\n",
      "1.2202072143554688\n",
      "1.48627507686615\n",
      "1.029080867767334\n",
      "1.0763130187988281\n",
      "1.2169603109359741\n",
      "1.4324545860290527\n",
      "1.9777722358703613\n",
      "1.1364822387695312\n",
      "1.6229233741760254\n",
      "1.29798424243927\n",
      "1.3328421115875244\n",
      "1.5058040618896484\n",
      "1.3309221267700195\n",
      "1.0012084245681763\n",
      "1.1171799898147583\n",
      "1.970812439918518\n",
      "1.5195035934448242\n",
      "1.0801068544387817\n",
      "0.9926481246948242\n",
      "1.6654831171035767\n",
      "1.1064770221710205\n",
      "1.0482491254806519\n",
      "1.4813237190246582\n",
      "2.09667706489563\n",
      "1.0865398645401\n",
      "0.981286883354187\n",
      "1.0645544528961182\n",
      "1.0250521898269653\n",
      "1.1542381048202515\n",
      "1.8285565376281738\n",
      "0.8556894063949585\n",
      "1.1850769519805908\n",
      "1.1970547437667847\n",
      "1.3621020317077637\n",
      "1.1895651817321777\n",
      "1.1423146724700928\n",
      "1.2178947925567627\n",
      "0.7890106439590454\n",
      "1.0197018384933472\n",
      "2.5602548122406006\n",
      "1.1052625179290771\n",
      "1.1049892902374268\n",
      "1.6898664236068726\n",
      "1.0909165143966675\n",
      "1.202415943145752\n",
      "1.2286391258239746\n",
      "0.9650785326957703\n",
      "1.1926957368850708\n",
      "1.2556860446929932\n",
      "0.9234577417373657\n",
      "1.3376728296279907\n",
      "1.4813719987869263\n",
      "0.9123011231422424\n",
      "1.83353590965271\n",
      "1.08188796043396\n",
      "1.1946882009506226\n",
      "1.3140500783920288\n",
      "1.029158592224121\n",
      "0.8912662267684937\n",
      "1.706583857536316\n",
      "1.0008903741836548\n",
      "1.4550851583480835\n",
      "1.0449038743972778\n",
      "2.5785751342773438\n",
      "1.1557652950286865\n",
      "1.1590466499328613\n",
      "1.785819411277771\n",
      "2.0668609142303467\n",
      "1.1685956716537476\n",
      "1.6477724313735962\n",
      "1.733992576599121\n",
      "1.1258409023284912\n",
      "1.1371289491653442\n",
      "1.5823805332183838\n",
      "1.8540050983428955\n",
      "1.3068454265594482\n",
      "1.2629460096359253\n",
      "1.236834168434143\n",
      "1.6573978662490845\n",
      "0.8456889390945435\n",
      "1.4540438652038574\n",
      "1.066693902015686\n",
      "1.009657621383667\n",
      "0.9421558380126953\n",
      "1.433213233947754\n",
      "1.5587705373764038\n",
      "0.8574140667915344\n",
      "1.0249155759811401\n",
      "1.0166401863098145\n",
      "1.4426071643829346\n",
      "1.0506911277770996\n",
      "1.0037885904312134\n",
      "1.4486171007156372\n",
      "1.0569660663604736\n",
      "1.1133681535720825\n",
      "1.3180932998657227\n",
      "1.0438541173934937\n",
      "1.4182336330413818\n",
      "1.0301854610443115\n",
      "1.0450531244277954\n",
      "1.1081854104995728\n",
      "1.1637036800384521\n",
      "1.142677903175354\n",
      "0.9564787149429321\n",
      "1.63649320602417\n",
      "1.5734388828277588\n",
      "1.2378103733062744\n",
      "1.2486363649368286\n",
      "1.2806358337402344\n",
      "1.303409218788147\n",
      "1.2574477195739746\n",
      "1.2370285987854004\n",
      "1.3814265727996826\n",
      "1.3649541139602661\n",
      "1.52560555934906\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # load data\n",
    "    graph_gt, edge_index, x = batch\n",
    "    graph_gt = graph_gt.squeeze_(0).to(device)\n",
    "    labels = graph_gt.flatten()\n",
    "    edge_index = edge_index.squeeze_(0).to(device)\n",
    "    x = x.squeeze_(0).to(device)\n",
    "    \n",
    "    # make prediction\n",
    "    optimizer.zero_grad()\n",
    "    out = model(edge_index, x)\n",
    "    logits = out.flatten()\n",
    "    loss = criterion(logits, labels)\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if i % 50 == 0: print(loss.item())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bbba4a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22540\\410473758.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgraph_gt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # load data\n",
    "    graph_gt, edge_index, x = batch\n",
    "    graph_gt = graph_gt.squeeze_(0).to(device)\n",
    "    labels = graph_gt.flatten()\n",
    "    edge_index = edge_index.squeeze_(0).to(device)\n",
    "    x = x.squeeze_(0).to(device)\n",
    "    \n",
    "    # make prediction\n",
    "    with torch.no_grad():\n",
    "        A = model(edge_index, x)\n",
    "    acc.append(torch.mean(1.0*( 1.0*(A.detach().cpu()>0.5) == graph_gt[0])).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb3a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e5490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b5391",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "sig = nn.Sigmoid()\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # load data\n",
    "    graph_gt, graph_del, graph_ins, index = batch\n",
    "    graph_del = graph_del.to(device)\n",
    "    graph_ins = graph_ins.to(device)\n",
    "    \n",
    "    # prediction\n",
    "    with torch.no_grad():\n",
    "        A = graph_model(graph_del, graph_ins)\n",
    "    preds = [ sig(A[index[i]:index[i+1], index[i]:index[i+1]].detach().cpu())>0.5 for i in range(len(index)-1)]\n",
    "    for p in range(len(preds)):\n",
    "        acc.append(torch.mean(1.0*(preds[p] == graph_gt[p])).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
